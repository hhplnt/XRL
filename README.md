# XRL Project

### Description
An investigation into the use of causal reasoning in explaining the decisions of DeepRL agents in the context of cyber network defense. 
This project was produced to contribute to the award of MSc Mathematics of Cybersecurity at the University of Bristol.

### Abstract
The use of DeepRL techniques in training autonomous agents to defend cyber networks is gaining popularity. However, such methods are essentially `black boxes', making agents difficult to trust, understand and verify. An emerging field of research attempts to provide explanations for the decisions of RL agents, and in this paper I review the achievements and limitations of these studies. Research from the cognitive sciences indicates that human understanding is fundamentally linked to causal relationships, yet few methods have been proposed which use causal models to generate explanations. Thus, in this paper, I explore a mechanism which wields a structural causal model to derive local, post-hoc explanaions of RL agent actions and specifically adapt this for cyber defence applications. This model is tested using the cyber simulator YAWNING TITAN, and evaluated through an example network defence scenario to demonstrate the insights which can be derived.
